{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20474ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9399d6ab",
   "metadata": {},
   "source": [
    "# Problem Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25a198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = 'PD_modelling_dataset.xlsx'\n",
    "data = pd.read_excel(file_path, sheet_name='dataset')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebcf45b",
   "metadata": {},
   "source": [
    "### Need of the Study/Project:\n",
    "In the role of a data scientist, it is essential to understand why this study or project is necessary:\n",
    "\n",
    "Risk Management:\n",
    "\n",
    "Credit Risk: Predicting the probability of default helps in assessing the credit risk associated with each customer. By identifying high-risk customers, the company can take preventive measures to mitigate potential losses.\n",
    "Portfolio Management: Understanding the risk profile of customers allows for better management of the credit portfolio, ensuring a balanced risk-return trade-off.\n",
    "Financial Stability:\n",
    "\n",
    "Provisioning and Reserves: Accurate PD modeling helps in determining the amount of reserves required to cover potential losses. This ensures the financial stability and health of the organization.\n",
    "Capital Allocation: Efficient capital allocation based on risk assessment ensures that resources are optimally utilized, contributing to the overall profitability of the company.\n",
    "Regulatory Compliance:\n",
    "\n",
    "Compliance with Standards: Financial institutions are required to comply with regulatory standards such as Basel III, which mandates robust risk assessment and management practices. PD modeling is a key component of these requirements.\n",
    "Transparency: Predictive models provide transparency in credit decision-making processes, which is crucial for regulatory reporting and audit purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94cdc9f",
   "metadata": {},
   "source": [
    "### Understanding Business/Social Opportunity:\n",
    "The project presents several business and social opportunities:\n",
    "\n",
    "Enhanced Customer Experience:\n",
    "\n",
    "Personalized Services: By understanding the risk profile of customers, the company can offer personalized credit products and services tailored to individual needs and risk levels.\n",
    "Proactive Customer Support: Identifying customers at risk of default allows for proactive engagement and support, such as offering restructuring options or financial counseling.\n",
    "Competitive Advantage:\n",
    "\n",
    "Data-Driven Decisions: Leveraging predictive analytics provides a competitive edge by enabling data-driven decision-making. This can lead to improved credit approval processes, optimized interest rates, and better customer retention strategies.\n",
    "Market Positioning: Companies with robust risk management practices are perceived as more reliable and stable, enhancing their market reputation and attracting more customers.\n",
    "Social Impact:\n",
    "\n",
    "Financial Inclusion: By accurately assessing credit risk, the company can extend credit to underserved segments of the population, promoting financial inclusion.\n",
    "Economic Stability: Reducing the incidence of defaults contributes to the stability of the financial system, which in turn supports broader economic stability and growth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fd0abf",
   "metadata": {},
   "source": [
    "# Data Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of rows and columns\n",
    "num_rows, num_columns = data.shape\n",
    "\n",
    "print(f\"\\nNumber of Rows: {num_rows}\")\n",
    "print(f\"Number of Columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a734d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50acb5b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nDataset Description:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358809b1",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac2dfac",
   "metadata": {},
   "source": [
    "### a) Univariate analysis (distribution and spread for every continuous attribute, distribution of data in categories for categorical ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a48f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate continuous and categorical variables\n",
    "continuous_vars = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_vars = data.select_dtypes(include=['object', 'category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992db375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis for continuous variables\n",
    "for var in continuous_vars:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(data[var].dropna(), kde=True, bins=30)\n",
    "    plt.title(f'Histogram of {var}')\n",
    "\n",
    "    # Box plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=data[var].dropna())\n",
    "    plt.title(f'Box Plot of {var}')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e4539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Univariate analysis for categorical variables\n",
    "for var in categorical_vars:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Bar plot\n",
    "    sns.countplot(y=data[var])\n",
    "    plt.title(f'Bar Plot of {var}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d28f2",
   "metadata": {},
   "source": [
    "### b) Bivariate analysis (relationship between different variables , correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba43dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate continuous and categorical variables\n",
    "continuous_vars = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_vars = data.select_dtypes(include=['object', 'category']).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469edd2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bivariate analysis: Continuous vs Continuous\n",
    "print(\"Correlation Matrix:\\n\")\n",
    "correlation_matrix = data[continuous_vars].corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "\n",
    "for i in range(len(continuous_vars)):\n",
    "    for j in range(i + 1, len(continuous_vars)):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.scatterplot(x=data[continuous_vars[i]], y=data[continuous_vars[j]])\n",
    "        plt.title(f'Scatter Plot between {continuous_vars[i]} and {continuous_vars[j]}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b960fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate analysis: Continuous vs Continuous\n",
    "\n",
    "# Select continuous variables\n",
    "continuous_vars = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = data[continuous_vars].corr()\n",
    "\n",
    "# Plot heatmap with improved readability\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, \n",
    "            annot_kws={\"size\": 10}, fmt=\".2f\", linewidths=.5, cbar_kws={\"shrink\": .75})\n",
    "\n",
    "plt.title('Correlation Matrix', fontsize=20)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate analysis: Categorical vs Categorical\n",
    "for i in range(len(categorical_vars)):\n",
    "    for j in range(i + 1, len(categorical_vars)):\n",
    "        crosstab = pd.crosstab(data[categorical_vars[i]], data[categorical_vars[j]])\n",
    "        print(f'\\nCrosstab between {categorical_vars[i]} and {categorical_vars[j]}:\\n')\n",
    "        print(crosstab)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(crosstab, annot=True, cmap='Blues')\n",
    "        plt.title(f'Heatmap of {categorical_vars[i]} vs {categorical_vars[j]}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80a8bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bivariate analysis: Continuous vs Categorical\n",
    "for cat in categorical_vars:\n",
    "    for cont in continuous_vars:\n",
    "        plt.figure(figsize=(14, 8))  # Increase the figure size for better readability\n",
    "        sns.boxplot(x=data[cat], y=data[cont])\n",
    "        plt.title(f'Box Plot of {cont} by {cat}', fontsize=16)\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=12)  # Rotate x-axis labels\n",
    "        plt.xlabel(cat, fontsize=14)\n",
    "        plt.ylabel(cont, fontsize=14)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(14, 8))  # Increase the figure size for better readability\n",
    "        sns.violinplot(x=data[cat], y=data[cont])\n",
    "        plt.title(f'Violin Plot of {cont} by {cat}', fontsize=16)\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=12)  # Rotate x-axis labels\n",
    "        plt.xlabel(cat, fontsize=14)\n",
    "        plt.ylabel(cont, fontsize=14)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916e0c26",
   "metadata": {},
   "source": [
    "### c) Missing Value treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a40c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"\\nMissing Values per Column:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "data_dropped_rows = data.dropna()\n",
    "\n",
    "# Drop columns with missing values\n",
    "data_dropped_columns = data.dropna(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and categorical columns\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Mean Imputation for numerical columns\n",
    "data_mean_imputed = data.copy()\n",
    "data_mean_imputed[numerical_cols] = data[numerical_cols].fillna(data[numerical_cols].mean())\n",
    "\n",
    "# Median Imputation for numerical columns\n",
    "data_median_imputed = data.copy()\n",
    "data_median_imputed[numerical_cols] = data[numerical_cols].fillna(data[numerical_cols].median())\n",
    "\n",
    "# Mode Imputation for categorical columns\n",
    "data_mode_imputed = data.copy()\n",
    "for col in categorical_cols:\n",
    "    data_mode_imputed[col].fillna(data[col].mode()[0], inplace=True)\n",
    "\n",
    "# Forward Fill for both numerical and categorical columns\n",
    "data_ffill_imputed = data.copy()\n",
    "data_ffill_imputed.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Backward Fill for both numerical and categorical columns\n",
    "data_bfill_imputed = data.copy()\n",
    "data_bfill_imputed.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Display the first few rows of the imputed datasets\n",
    "print(\"\\nData after Mean Imputation:\\n\", data_mean_imputed.head())\n",
    "print(\"\\nData after Median Imputation:\\n\", data_median_imputed.head())\n",
    "print(\"\\nData after Mode Imputation:\\n\", data_mode_imputed.head())\n",
    "print(\"\\nData after Forward Fill:\\n\", data_ffill_imputed.head())\n",
    "print(\"\\nData after Backward Fill:\\n\", data_bfill_imputed.head())\n",
    "\n",
    "# Verify that there are no more missing values in each imputed dataset\n",
    "print(\"\\nMissing Values per Column after Mean Imputation:\\n\", data_mean_imputed.isnull().sum())\n",
    "print(\"\\nMissing Values per Column after Median Imputation:\\n\", data_median_imputed.isnull().sum())\n",
    "print(\"\\nMissing Values per Column after Mode Imputation:\\n\", data_mode_imputed.isnull().sum())\n",
    "print(\"\\nMissing Values per Column after Forward Fill:\\n\", data_ffill_imputed.isnull().sum())\n",
    "print(\"\\nMissing Values per Column after Backward Fill:\\n\", data_bfill_imputed.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c075ef",
   "metadata": {},
   "source": [
    "### d) Outlier treatment (if required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a4469b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Separate numerical columns\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Function to detect and treat outliers using Z-Score method\n",
    "def zscore_outlier_treatment(df, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(df))\n",
    "    df_outliers_removed = df[(z_scores < threshold).all(axis=1)]\n",
    "    return df_outliers_removed\n",
    "\n",
    "# Function to detect and treat outliers using IQR method\n",
    "def iqr_outlier_treatment(df):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df_outliers_removed = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    return df_outliers_removed\n",
    "\n",
    "# Z-Score Method\n",
    "data_zscore_treated = zscore_outlier_treatment(data[numerical_cols])\n",
    "\n",
    "# IQR Method\n",
    "data_iqr_treated = iqr_outlier_treatment(data[numerical_cols])\n",
    "\n",
    "# Visualization: Boxplots for visual inspection of outliers\n",
    "plt.figure(figsize=(15, 10))\n",
    "num_plots = len(numerical_cols)\n",
    "cols = 3\n",
    "rows = (num_plots // cols) + (num_plots % cols > 0)\n",
    "\n",
    "for i, col in enumerate(numerical_cols, 1):\n",
    "    plt.subplot(rows, cols, i)\n",
    "    sns.boxplot(x=data[col])\n",
    "    plt.title(f'Box Plot of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization: Scatterplots for visual inspection of outliers\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(numerical_cols, 1):\n",
    "    plt.subplot(rows, cols, i)\n",
    "    sns.scatterplot(x=data.index, y=data[col])\n",
    "    plt.title(f'Scatter Plot of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the shape of the datasets after outlier treatment\n",
    "print(\"\\nOriginal Data Shape:\", data.shape)\n",
    "print(\"Data Shape after Z-Score Outlier Treatment:\", data_zscore_treated.shape)\n",
    "print(\"Data Shape after IQR Outlier Treatment:\", data_iqr_treated.shape)\n",
    "\n",
    "# Verify that the outliers have been removed\n",
    "print(\"\\nSummary Statistics after Z-Score Outlier Treatment:\\n\", data_zscore_treated.describe())\n",
    "print(\"\\nSummary Statistics after IQR Outlier Treatment:\\n\", data_iqr_treated.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664cf03b",
   "metadata": {},
   "source": [
    "### e) Variable transformation (if applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Step 1: Fill missing values (example: using mean imputation for numeric columns)\n",
    "numeric_columns = data.select_dtypes(include=[np.number]).columns\n",
    "data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].mean())\n",
    "\n",
    "# Step 2: Ensure all categorical variables are uniformly of type str\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    data[column] = data[column].astype(str)\n",
    "\n",
    "\n",
    "# Encode categorical variables (example using LabelEncoder for simplicity)\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Step 3: Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
    "\n",
    "# Step 4: Split the data (optional, usually for supervised learning, but shown here for completeness)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the first few rows of the processed data to verify the transformations\n",
    "print(data.head())\n",
    "\n",
    "# Check for any remaining missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Check the data types to ensure all columns are appropriately typed\n",
    "print(data.dtypes)\n",
    "\n",
    "# Plot histograms for numerical features\n",
    "data.hist(bins=30, figsize=(20, 15))\n",
    "plt.show()\n",
    "\n",
    "# Check distribution of categorical variables\n",
    "for column in data.select_dtypes(include=['int']).columns:\n",
    "    sns.countplot(data[column])\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58710f72",
   "metadata": {},
   "source": [
    "# Business insights from EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe507a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn pandas numpy matplotlib seaborn joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b29c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "# Assuming train_data is your DataFrame and numeric_columns is your list of numeric columns\n",
    "\n",
    "# Select features for clustering (excluding the target variable if applicable)\n",
    "features = train_data.drop(columns=['default'])\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=0)\n",
    "train_data['Cluster'] = kmeans.fit_predict(features)\n",
    "\n",
    "# Analyze clusters\n",
    "cluster_analysis = train_data.groupby('Cluster')[numeric_columns].mean()\n",
    "print(\"\\nCluster Analysis:\\n\", cluster_analysis)\n",
    "\n",
    "# Visualize the clusters using PCA for 2D visualization\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(features)\n",
    "train_data['PCA1'] = principal_components[:, 0]\n",
    "train_data['PCA2'] = principal_components[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(train_data['PCA1'], train_data['PCA2'], c=train_data['Cluster'], cmap='viridis')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('PCA of Clusters')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()\n",
    "\n",
    "# Validate clusters using silhouette score\n",
    "silhouette_avg = silhouette_score(features, train_data['Cluster'])\n",
    "print(f'Silhouette Score: {silhouette_avg}')\n",
    "\n",
    "# Save label encoders and scaler for future use\n",
    "for column, le in label_encoders.items():\n",
    "    joblib.dump(le, f'label_encoder_{column}.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc0155e",
   "metadata": {},
   "source": [
    "\n",
    "The PCA plot you provided visualizes the clustering results of your data. Each point represents a data instance projected onto two principal components (PCA Component 1 and PCA Component 2), and the colors indicate the cluster assignments. Here's how we can derive some business insights from this plot:\n",
    "\n",
    "1. Cluster Distribution and Separation:\n",
    "The plot shows distinct clusters indicating that the KMeans algorithm successfully identified groups of similar instances.\n",
    "Good separation between clusters suggests that the features used for clustering are effective in distinguishing between different patterns in the data.\n",
    "2. Cluster Characteristics:\n",
    "To gain business insights, we should look at the average values of key metrics for each cluster (which we already calculated). For instance, clusters might represent different segments of customers based on their credit behavior.\n",
    "Analyzing the cluster_analysis output will help identify unique characteristics of each cluster.\n",
    "3. Potential Actions for Each Cluster:\n",
    "Cluster 0: If this cluster has higher default rates, you might want to implement stricter credit policies or additional monitoring for this group.\n",
    "Cluster 1: If this cluster shows strong financial health (e.g., low default rates, high paid amounts), they could be targeted for new credit products or upselling.\n",
    "Cluster 2: If this group is in between the high-risk and low-risk segments, tailored offers or educational content about financial management could be beneficial.\n",
    "Cluster 3: This cluster might represent a niche segment with unique characteristics. Understanding their needs could help in designing specific financial products.\n",
    "Cluster 4: If this cluster shows diverse behavior, more granular segmentation might be needed.\n",
    "4. Market Strategy:\n",
    "Marketing and Customer Engagement: Use the cluster insights to create targeted marketing campaigns. For example, offering lower interest rates to low-risk clusters and personalized repayment plans to high-risk clusters.\n",
    "Product Development: Develop financial products tailored to the needs of each cluster, like premium credit cards for low-risk customers and secured cards for high-risk customers.\n",
    "5. Risk Management:\n",
    "Use the cluster information to better manage risk by adjusting credit limits, interest rates, and approval criteria based on the risk profile of each cluster.\n",
    "6. Operational Efficiency:\n",
    "Optimize resource allocation by focusing more on high-value or high-risk clusters. This could involve providing more personalized customer service to profitable clusters or investing in risk mitigation for high-risk clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92311622",
   "metadata": {},
   "source": [
    "### 1. Model building and interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "file_path = 'PD_modelling_dataset.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Identify feature and target columns\n",
    "# Assuming the target column is named 'default'\n",
    "X = df.drop('default', axis=1)\n",
    "y = df['default']\n",
    "\n",
    "# Handle missing values and encode categorical variables\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Drop rows with NaN in y_train (if any)\n",
    "y_train.dropna(inplace=True)\n",
    "\n",
    "# Drop corresponding rows in X_train to maintain consistency\n",
    "X_train = X_train.loc[y_train.index]\n",
    "\n",
    "# Apply transformations\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d67d78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in y_train:\", y_train.isnull().sum())\n",
    "\n",
    "# Check shapes to ensure consistency\n",
    "print(\"X_train shape after handling NaNs:\", X_train.shape)\n",
    "print(\"y_train shape after handling NaNs:\", y_train.shape)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3edddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "# Plot heatmap of confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Default', 'Default'], yticklabels=['No Default', 'Default'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC curve and AUC score\n",
    "y_pred_prob = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "auc_score = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f'AUC Score: {auc_score:.2f}')\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41528fd3",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8865a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Remove unexpected class '10000.0' from y_test and corresponding X_test\n",
    "mask = y_test != 10000.0\n",
    "y_test = y_test[mask]\n",
    "X_test = X_test[mask]\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "# Plot heatmap of confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Default', 'Default'], yticklabels=['No Default', 'Default'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC curve and AUC score\n",
    "y_pred_prob = dt_classifier.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "auc_score = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f'AUC Score: {auc_score:.2f}')\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f3db2d",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a7cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "\n",
    "# Impute missing values in X_train and X_test\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Remove unexpected class '10000.0' from y_train and y_test\n",
    "mask_train = y_train != 10000.0\n",
    "y_train = y_train[mask_train]\n",
    "X_train = X_train[mask_train]\n",
    "\n",
    "mask_test = y_test != 10000.0\n",
    "y_test = y_test[mask_test]\n",
    "X_test = X_test[mask_test]\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_classifier = SVC(probability=True, random_state=42)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "# Plot heatmap of confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Default', 'Default'], yticklabels=['No Default', 'Default'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC curve and AUC score\n",
    "y_pred_prob = svm_classifier.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "auc_score = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f'AUC Score: {auc_score:.2f}')\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17600766",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae5aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "\n",
    "# Impute missing values in X_train and X_test\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Remove unexpected class '10000.0' from y_train and y_test\n",
    "mask_train = y_train != 10000.0\n",
    "y_train = y_train[mask_train]\n",
    "X_train = X_train[mask_train]\n",
    "\n",
    "mask_test = y_test != 10000.0\n",
    "y_test = y_test[mask_test]\n",
    "X_test = X_test[mask_test]\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "# Plot heatmap of confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Default', 'Default'], yticklabels=['No Default', 'Default'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC curve and AUC score\n",
    "y_pred_prob = nb_classifier.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "auc_score = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f'AUC Score: {auc_score:.2f}')\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3edadca",
   "metadata": {},
   "source": [
    "### 2. Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ea678a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "\n",
    "# Impute missing values in X_train and X_test\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Remove unexpected class '10000.0' from y_train and y_test\n",
    "mask_train = y_train != 10000.0\n",
    "y_train = y_train[mask_train]\n",
    "X_train = X_train[mask_train]\n",
    "\n",
    "mask_test = y_test != 10000.0\n",
    "y_test = y_test[mask_test]\n",
    "X_test = X_test[mask_test]\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_prob)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "    \n",
    "    # Plot heatmap of confusion matrix\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Default', 'Default'], yticklabels=['No Default', 'Default'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix Heatmap')\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {auc_score:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc_score': auc_score\n",
    "    }\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "\n",
    "# GradientBoostingClassifier\n",
    "print(\"\\nGradientBoostingClassifier Results:\")\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "results['GradientBoosting'] = evaluate_model(gb_classifier, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# StackingClassifier\n",
    "print(\"\\nStackingClassifier Results:\")\n",
    "estimators = [('rf', RandomForestClassifier(random_state=42)),\n",
    "              ('gb', GradientBoostingClassifier(random_state=42))]\n",
    "stacking_classifier = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "results['Stacking'] = evaluate_model(stacking_classifier, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Compare results\n",
    "print(\"\\nComparison of Model Performance:\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"  {metric_name}: {value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7852d68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined and preprocessed\n",
    "\n",
    "# Impute missing values in X_train and X_test\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Remove unexpected class '10000.0' from y_train and y_test\n",
    "mask_train = y_train != 10000.0\n",
    "y_train = y_train[mask_train]\n",
    "X_train = X_train[mask_train]\n",
    "\n",
    "mask_test = y_test != 10000.0\n",
    "y_test = y_test[mask_test]\n",
    "X_test = X_test[mask_test]\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_prob)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "    \n",
    "    # Plot heatmap of confusion matrix\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Default', 'Default'], yticklabels=['No Default', 'Default'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix Heatmap')\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {auc_score:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc_score': auc_score\n",
    "    }\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# RandomForestClassifier\n",
    "print(\"RandomForestClassifier Results:\")\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "results['Random Forest Classifier'] = evaluate_model(rf_classifier, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# DecisionTreeClassifier\n",
    "print(\"\\nDecisionTreeClassifier Results:\")\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "results['Decision Tree Classifier'] = evaluate_model(dt_classifier, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Support Vector Machine\n",
    "print(\"\\nSupport Vector Machine Results:\")\n",
    "svm_classifier = SVC(probability=True, random_state=42)\n",
    "results['Support Vector Machine'] = evaluate_model(svm_classifier, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "print(\"\\nNaive Bayes Classifier Results:\")\n",
    "nb_classifier = GaussianNB()\n",
    "results['Naive Bayes Classifier'] = evaluate_model(nb_classifier, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Bagging Classifier\n",
    "print(\"\\nBaggingClassifier Results:\")\n",
    "bagging_classifier = BaggingClassifier(random_state=42)\n",
    "results['Bagging Classifier'] = evaluate_model(bagging_classifier, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# AdaBoostClassifier\n",
    "print(\"\\nAdaBoostClassifier Results:\")\n",
    "ada_classifier = AdaBoostClassifier(random_state=42)\n",
    "results['Ada Boost Classifier'] = evaluate_model(ada_classifier, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# GradientBoostingClassifier\n",
    "print(\"\\nGradientBoostingClassifier Results:\")\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "results['Gradient Boosting Classifier'] = evaluate_model(gb_classifier, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# StackingClassifier\n",
    "print(\"\\nStackingClassifier Results:\")\n",
    "estimators = [('rf', RandomForestClassifier(random_state=42)),\n",
    "              ('gb', GradientBoostingClassifier(random_state=42))]\n",
    "stacking_classifier = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "results['Stacking'] = evaluate_model(stacking_classifier, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "# Compare results\n",
    "print(\"\\nComparison of Model Performance:\")\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "print(comparison_df)\n",
    "\n",
    "# Display the comparison in tabular format\n",
    "comparison_df.reset_index(inplace=True)\n",
    "comparison_df.columns = ['Model Name', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC Score']\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb880f6",
   "metadata": {},
   "source": [
    "### Choosing the Optimum Model\n",
    "The Gradient Boosting Classifier and Stacking models stand out with high AUC Scores of 0.897468 and 0.881665, respectively. These models indicate a good balance between distinguishing positive and negative classes.\n",
    "\n",
    "The Random Forest Classifier has the highest accuracy, but its recall is very low, indicating it misses a large number of actual positives. On the other hand, the Naive Bayes Classifier has the highest recall but suffers from very low accuracy and precision.\n",
    "\n",
    "Considering a balance of accuracy, precision, recall, F1-score, and AUC score, Gradient Boosting Classifier appears to be the most optimum model.\n",
    "\n",
    "##### Implications on the Business\n",
    "###### Using the Gradient Boosting Classifier can provide the following benefits to the business:\n",
    "\n",
    "Improved Prediction Accuracy: Higher accuracy and AUC scores indicate better performance in distinguishing between classes, leading to more reliable predictions.\n",
    "\n",
    "Balanced Performance: Good precision and recall balance, ensuring fewer false positives and false negatives, which is crucial for decision-making processes.\n",
    "\n",
    "Customer Satisfaction: Reliable predictions can improve customer satisfaction by providing accurate results, enhancing trust in the system.\n",
    "\n",
    "Resource Allocation: Better prediction performance can optimize resource allocation, ensuring efforts and investments are directed towards the right areas.\n",
    "\n",
    "Risk Management: Enhanced ability to predict and manage risks by accurately identifying potential issues or opportunities.\n",
    "Adopting the Gradient Boosting Classifier can significantly enhance the business's decision-making capabilities, leading to better outcomes and improved efficiency.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304220da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
